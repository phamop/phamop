# Optimized OpenTelemetry Collector Configuration for AKS Service Discovery
mode: "daemonset" # Deploy as a DaemonSet to run on each node for host-level telemetry

presets:
  logsCollection:
    enabled: true
    includeCollectorLogs: false
    storeCheckpoints: false
    maxRecombineLogSize: 102400
  hostMetrics:
    enabled: true
  # Enable kubernetesAttributes to enrich telemetry with Kubernetes metadata.
  # This is crucial for effective service discovery and correlation.
  kubernetesAttributes:
    enabled: true
    extract:
      # Extract common Kubernetes resource attributes
      - metadata.name
      - metadata.namespace
      - metadata.labels
      - metadata.annotations
      - spec.nodeName
      - status.podIP
    # Configure resolvers to identify pods by their IP addresses for attribute enrichment
    pod_association:
      - from: "connection"
      - from: "resource_attribute"
        name: "k8s.pod.ip" # This is the default, ensuring enrichment works if the IP is already an attribute
  kubeletMetrics:
    enabled: true
  kubernetesEvents:
    # Enabling Kubernetes Events can be useful for comprehensive observability.
    # Consider enabling if you need to track cluster events.
    enabled: false
  clusterMetrics:
    # Enabling clusterMetrics requires appropriate RBAC permissions.
    # It's useful for cluster-level insights (e.g., node conditions, deployments).
    enabled: false

configMap:
  create: true
  existingName: "" # Leave empty if you want the Helm chart to create it.

internalTelemetryViaOTLP:
  endpoint: "" # Keep empty if not exporting collector's internal telemetry via OTLP
  headers: []
  traces:
    enabled: false
  metrics:
    enabled: false
  logs:
    enabled: false

config:
  receivers:
    otlp:
      protocols:
        grpc:
          # Bind to 0.0.0.0 to accept connections from other pods/services within the cluster
          endpoint: "0.0.0.0:4317"
        http:
          # Bind to 0.0.0.0 to accept connections from other pods/services within the cluster
          endpoint: "0.0.0.0:4318"
    jaeger:
      protocols:
        grpc:
          endpoint: "0.0.0.0:14250"
        thrift_http:
          endpoint: "0.0.0.0:14268"
        thrift_compact:
          endpoint: "0.0.0.0:6831"
    zipkin:
      endpoint: "0.0.0.0:9411"
    kubeletstats:
      # AKS Kubelet API uses self-signed certificates, so skip verification.
      # Ensure your service account has the necessary permissions to access kubelet.
      insecure_skip_verify: true
      collection_interval: 10s # Example: Adjust as needed
      auth:
        # Use service account token for authentication
        token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      metric_groups:
        - "node"
        - "pod"
    prometheus:
      config:
        scrape_configs:
          # Scrape the OpenTelemetry Collector's own metrics
          - job_name: opentelemetry-collector
            scrape_interval: 10s
            # Use Kubernetes service discovery for the collector itself
            kubernetes_sd_configs:
              - role: pod
            relabel_configs:
              # Target the collector's own metrics endpoint
              - source_labels: [__meta_kubernetes_pod_name]
                regex: ".*opentelemetry-collector.*" # Adjust if your collector pod name pattern differs
                action: keep
              - source_labels: [__meta_kubernetes_pod_container_port_name]
                regex: "metrics" # Assuming the Prometheus metrics port is named "metrics"
                action: keep
              - source_labels: [__meta_kubernetes_pod_ip, __meta_kubernetes_pod_container_port_number]
                regex: "(.+);(.+)"
                replacement: "$${1}:$${2}"
                target_label: __address__
          # Example: Kubernetes Pod/Service discovery for application metrics
          # This is the core for service discovery in AKS
          - job_name: kubernetes-pods
            scrape_interval: 30s # Adjust scrape interval as needed
            kubernetes_sd_configs:
              - role: pod
            relabel_configs:
              # Example: Only scrape pods with a specific annotation for Prometheus metrics
              # Add this annotation to your application pods: prometheus.io/scrape: "true"
              - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
                action: keep
                regex: "true"
              # Example: Use the annotation prometheus.io/path to specify the metrics path
              - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
                action: replace
                target_label: __metrics_path__
                regex: (.+)
              # Example: Use the annotation prometheus.io/port to specify the metrics port
              - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_port]
                action: replace
                target_label: __address__
                regex: (.+)
                replacement: "$${1}:$$2" # This will be the pod IP and annotated port
              - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
                regex: "([^:]+)(?::\\d+)?;(\\d+)"
                replacement: "$${1}:$${2}"
                target_label: __address__
              # Add Kubernetes metadata as labels
              - source_labels: [__meta_kubernetes_namespace]
                action: replace
                target_label: kubernetes_namespace
              - source_labels: [__meta_kubernetes_pod_name]
                action: replace
                target_label: kubernetes_pod_name
              - source_labels: [__meta_kubernetes_container_name]
                action: replace
                target_label: kubernetes_container_name
              # You can add more relabelings to extract other Kubernetes metadata as labels

  processors:
    batch: {}
    memory_limiter:
      check_interval: 5s
      limit_percentage: 80
      spike_limit_percentage: 25
    # The kubernetesattributes processor is automatically enabled by the preset,
    # but explicitly listing it here for clarity if you were to manage processors manually.
    # kubernetesattributes:
    #   extract:
    #     - metadata.name
    #     - metadata.namespace
    #     - metadata.labels
    #     - metadata.annotations
    #     - spec.nodeName
    #     - status.podIP
    #   pod_association:
    #     - from: "connection"
    #     - from: "resource_attribute"
    #       name: "k8s.pod.ip"

  exporters:
    debug: {} # For debugging purposes, sends telemetry to stdout/stderr
    azuremonitor:
      # Ensure your connection string is securely managed (e.g., Kubernetes Secret)
      connection_string: "InstrumentationKey=a04b4a5d-40f2-4508-885a-6ba32f28d17b;IngestionEndpoint=https://eastus-8.in.applicationinsights.azure.com/;LiveEndpoint=https://eastus.livediagnostics.monitor.azure.com/;ApplicationId=0cac2de8-d983-4211-8a7a-709d6363d032"
    otlphttp/loki:
      endpoint: "http://loki:3100/otlp" # Ensure Loki service is reachable at this endpoint
    prometheus:
      endpoint: "0.0.0.0:8889" # Expose Prometheus metrics from the collector itself

  extensions:
    health_check:
      # Bind to 0.0.0.0 for reachability within the pod
      endpoint: "0.0.0.0:13133"

  service:
    telemetry:
      metrics:
        readers:
          - pull:
              exporter:
                prometheus:
                  host: "0.0.0.0" # Bind to 0.0.0.0 for external access
                  port: 8888
    extensions:
      - health_check
    pipelines:
      logs:
        receivers:
          - otlp
          # Add a filelog receiver for collecting container logs if needed.
          # This typically works best with a DaemonSet.
          # - filelog # Requires filelog receiver configuration
        processors:
          - memory_limiter
          - batch
          - kubernetesattributes # Ensure k8s attributes are added to logs
        exporters:
          - debug
          - azuremonitor
          - otlphttp/loki
      metrics:
        receivers:
          - otlp
          - prometheus
          - kubeletstats # Add kubeletstats to the metrics pipeline
        processors:
          - memory_limiter
          - batch
          - kubernetesattributes # Ensure k8s attributes are added to metrics
        exporters:
          - debug
          - azuremonitor
          - prometheus
      traces:
        receivers:
          - otlp
          - jaeger
          - zip
        processors:
          - memory_limiter
          - batch
          - kubernetesattributes # Ensure k8s attributes are added to traces
        exporters:
          - debug
          - azuremonitor
          - otlp # Assuming you want to export traces to another OTLP endpoint (e.g., Azure Monitor is OTLP compatible)

image:
  repository: "otel/opentelemetry-collector-contrib"
  pullPolicy: IfNotPresent
  tag: "0.123.0" # Use a specific, stable tag. Consider updating to the latest stable.

resources:
  requests:
    cpu: 500m
    memory: 800Mi
  limits:
    cpu: 2000m
    memory: 2000Mi

serviceAccount:
  create: true
  # Ensure the service account has necessary RBAC permissions for Kubernetes API access
  # for kubernetesAttributes processor and kubeletstats receiver.
  # This typically includes permissions to "get", "list", "watch" pods, nodes, services, endpoints.

ports:
  otlp:
    enabled: true
    containerPort: 4317
    servicePort: 4317 # Expose this as a Service to allow applications to send OTLP to the collector
    hostPort: 4317 # If running as DaemonSet and you want host-level port exposure
  otlp-http:
    enabled: true
    containerPort: 4318
    servicePort: 4318
    hostPort: 4318
  jaeger-compact:
    enabled: true
    containerPort: 6831
    protocol: UDP
    hostPort: 6831
  jaeger-thrift:
    enabled: true
    containerPort: 14268
    servicePort: 14268
    hostPort: 14268
  jaeger-grpc:
    enabled: true
    containerPort: 14250
    servicePort: 14250
    hostPort: 14250
  zipkin:
    enabled: true
    containerPort: 9411
    servicePort: 9411
    hostPort: 9411
  metrics: # Port for the collector's own internal Prometheus metrics
    enabled: true
    containerPort: 8888
    servicePort: 8888
    hostPort: 8888

livenessProbe:
  httpGet:
    path: /
    port: 13133
readinessProbe:
  httpGet:
    path: /
    port: 13133
  initialDelaySeconds: 5
  periodSeconds: 10

useGOMEMLIMIT: true
