# Optimized OpenTelemetry Collector Configuration for AKS Service Discovery
# Corrected for Helm Chart Schema Validation
mode: "daemonset" # Deploy as a DaemonSet to run on each node for host-level telemetry

presets:
  logsCollection:
    enabled: true
    includeCollectorLogs: false
    storeCheckpoints: false
    maxRecombineLogSize: 102400
  hostMetrics:
    enabled: true
  # *** CHANGE START ***
  # Remove 'extract' and 'pod_association' from presets.kubernetesAttributes
  # as per the error message. The chart likely configures this internally
  # or expects it under the main 'config' block.
  kubernetesAttributes:
    enabled: true
  # *** CHANGE END ***
  kubeletMetrics:
    enabled: true
  kubernetesEvents:
    enabled: false
  clusterMetrics:
    enabled: false

configMap:
  create: true
  existingName: "" # Leave empty if you want the Helm chart to create it.

internalTelemetryViaOTLP:
  endpoint: "" # Keep empty if not exporting collector's internal telemetry via OTLP
  headers: []
  traces:
    enabled: false
  metrics:
    enabled: false
  logs:
    enabled: false

config:
  receivers:
    otlp:
      protocols:
        grpc:
          endpoint: "0.0.0.0:4317"
        http:
          endpoint: "0.0.0.0:4318"
    jaeger:
      protocols:
        grpc:
          endpoint: "0.0.0.0:14250"
        thrift_http:
          endpoint: "0.0.0.0:14268"
        thrift_compact:
          endpoint: "0.0.0.0:6831"
    zipkin:
      endpoint: "0.0.0.0:9411"
    kubeletstats:
      insecure_skip_verify: true
      collection_interval: 10s # Example: Adjust as needed
      auth:
        token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      metric_groups:
        - "node"
        - "pod"
    prometheus:
      config:
        scrape_configs:
          # Scrape the OpenTelemetry Collector's own metrics
          - job_name: opentelemetry-collector
            scrape_interval: 10s
            kubernetes_sd_configs:
              - role: pod
            relabel_configs:
              - source_labels: [__meta_kubernetes_pod_name]
                regex: ".*opentelemetry-collector.*" # Adjust if your collector pod name pattern differs
                action: keep
              - source_labels: [__meta_kubernetes_pod_container_port_name]
                regex: "metrics" # Assuming the Prometheus metrics port is named "metrics"
                action: keep
              - source_labels: [__meta_kubernetes_pod_ip, __meta_kubernetes_pod_container_port_number]
                regex: "(.+);(.+)"
                replacement: "$${1}:$${2}"
                target_label: __address__

          # Kubernetes Pod/Service discovery for application metrics
          - job_name: kubernetes-pods
            scrape_interval: 30s # Adjust scrape interval as needed
            kubernetes_sd_configs:
              - role: pod
            relabel_configs:
              - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
                action: keep
                regex: "true"
              - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
                action: replace
                target_label: __metrics_path__
                regex: (.+)
              - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_port]
                action: replace
                target_label: __address__
                regex: (.+)
                replacement: "$${1}:$$2"
              - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
                regex: "([^:]+)(?::\\d+)?;(\\d+)"
                replacement: "$${1}:$${2}"
                target_label: __address__
              - source_labels: [__meta_kubernetes_namespace]
                action: replace
                target_label: kubernetes_namespace
              - source_labels: [__meta_kubernetes_pod_name]
                action: replace
                target_label: kubernetes_pod_name
              - source_labels: [__meta_kubernetes_container_name]
                action: replace
                target_label: kubernetes_container_name

  processors:
    batch: {}
    memory_limiter:
      check_interval: 5s
      limit_percentage: 80
      spike_limit_percentage: 25
    # *** CHANGE START ***
    # If the preset `kubernetesAttributes: enabled: true` doesn't fully configure
    # the processor as needed, you might need to explicitly define it here
    # under the 'processors' section, *if the chart allows custom processor definitions*.
    # If the error persists, it implies the chart takes full control of this processor.
    kubernetesattributes: # Define the processor explicitly if needed and allowed by chart
      extract:
        - metadata.name
        - metadata.namespace
        - metadata.labels
        - metadata.annotations
        - spec.nodeName
        - status.podIP
      pod_association:
        - from: "connection"
        - from: "resource_attribute"
          name: "k8s.pod.ip"
    # *** CHANGE END ***

  exporters:
    debug: {}
    azuremonitor:
        
    otlphttp/loki:
     endpoint: "http://loki-gateway.good9009.svc.cluster.local:3100/otlp"
    # endpoint: http://loki-gateway.good9009.svc.cluster.local:3100/otlp
    prometheus:
      endpoint: "0.0.0.0:8889"

  extensions:
    health_check:
      endpoint: "0.0.0.0:13133"

  service:
    telemetry:
      metrics:
        readers:
          - pull:
              exporter:
                prometheus:
                  host: "0.0.0.0"
                  port: 8888
    extensions:
      - health_check
    pipelines:
      logs:
        receivers:
          - otlp
        processors:
          - memory_limiter
          - batch
          - kubernetesattributes # Reference the processor defined above
        exporters:
          - debug
          - azuremonitor
          - otlphttp/loki
      metrics:
        receivers:
          - otlp
          - prometheus
          - kubeletstats
        processors:
          - memory_limiter
          - batch
          - kubernetesattributes # Reference the processor defined above
        exporters:
          - debug
          - azuremonitor
          - prometheus
      traces:
        receivers:
          - otlp
          - jaeger
          - zipkin
        processors:
          - memory_limiter
          - batch
          - kubernetesattributes # Reference the processor defined above
        exporters:
          - debug
          - azuremonitor
          - otlp

image:
  repository: "otel/opentelemetry-collector-contrib"
  pullPolicy: IfNotPresent
  tag: "0.123.0"

resources:
  requests:
    cpu: 200m
    memory: 260Mi
  limits:
    cpu: 1000m
    memory: 1000Mi

serviceAccount:
  create: true

ports:
  otlp:
    enabled: true
    containerPort: 4317
    servicePort: 4317
    hostPort: 4317
  otlp-http:
    enabled: true
    containerPort: 4318
    servicePort: 4318
    hostPort: 4318
  jaeger-compact:
    enabled: true
    containerPort: 6831
    protocol: UDP
    hostPort: 6831
  jaeger-thrift:
    enabled: true
    containerPort: 14268
    servicePort: 14268
    hostPort: 14268
  jaeger-grpc:
    enabled: true
    containerPort: 14250
    servicePort: 14250
    hostPort: 14250
  zipkin:
    enabled: true
    containerPort: 9411
    servicePort: 9411
    hostPort: 9411
  metrics:
    enabled: true
    containerPort: 8888
    servicePort: 8888
    hostPort: 8888

livenessProbe:
  httpGet:
    path: /
    port: 13133
readinessProbe:
  httpGet:
    path: /
    port: 13133
  initialDelaySeconds: 5
  periodSeconds: 10

useGOMEMLIMIT: true
