kubectl get opentelemetrycollectors.opentelemetry.io -n monitoring otelcollector -o yaml
apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"opentelemetry.io/v1beta1","kind":"OpenTelemetryCollector","metadata":{"annotations":{},"labels":{"app":"opentelemetry-collector"},"name":"otelcollector","namespace":"monitoring"},"spec":{"config":{"exporters":{"debug":{"verbosity":"basic"},"otlp/jaeger":{"endpoint":"http://jaeger-collector.monitoring.svc.cluster.local:4317","headers":{"X-Tenant-ID":"default"},"tls":{"insecure":true}},"otlphttp":{"endpoint":"http://loki-write.monitoring.svc.cluster.local:3100/otlp","headers":{"X-Scope-OrgID":"tenant-1"},"tls":{"insecure":true}},"prometheus":{"const_labels":{"k8s_cluster":"clustername"},"enable_open_metrics":true,"endpoint":"0.0.0.0:8889","namespace":"monitoring","send_timestamps":true}},"extensions":{"health_check":{"endpoint":"0.0.0.0:13133","path":"/health"},"pprof":{"endpoint":"0.0.0.0:1777"},"zpages":{"endpoint":"0.0.0.0:55679"}},"processors":{"batch":{"send_batch_max_size":4096,"send_batch_size":1024,"timeout":"200ms"},"groupbytrace":{},"memory_limiter":{"check_interval":"5s","limit_mib":512,"limit_percentage":80,"spike_limit_mib":64},"metricstransform":{"transforms":[{"action":"update","include":"system.cpu.usage","operations":[{"action":"add_label","new_label":"host.name","new_value":"host.name"},{"action":"add_label","new_label":"cluster.name","new_value":"clustername"}]},{"action":"update","include":"system.memory.usage","operations":[{"action":"add_label","new_label":"host.name","new_value":"host.name"},{"action":"add_label","new_label":"cluster.name","new_value":"clustername"}]}]},"resource":{"attributes":[{"action":"insert","from_attribute":"service.name","key":"service.name"},{"action":"insert","from_attribute":"k8s.container.name","key":"k8s.container.name"},{"action":"insert","from_attribute":"k8s.namespace.name","key":"k8s.namespace.name"},{"action":"insert","from_attribute":"k8s.pod.name","key":"k8s.pod.name"},{"action":"insert","from_attribute":"k8s.node.name","key":"k8s.node.name"},{"action":"insert","from_attribute":"host.name","key":"host.name"},{"action":"upsert","from_attribute":"service.name","key":"service.name"},{"action":"upsert","from_attribute":"service.namespace","key":"service.namespace"},{"action":"insert","key":"cluster.name","value":"clustername"}]},"resourcedetection":{"detectors":["env","system","kubernetes"],"override":false,"timeout":"2s"},"transform":{"log_statements":[{"context":"log","statements":["set(attributes[\"processing.note\"], \"Log enriched with resource and trace context\")","set(attributes[\"service.name\"], resource.attributes[\"service.name\"])","set(attributes[\"k8s.pod.name\"], resource.attributes[\"k8s.pod.name\"])","set(attributes[\"k8s.node.name\"], resource.attributes[\"k8s.node.name\"])","set(attributes[\"host.name\"], resource.attributes[\"host.name\"])","set(attributes[\"cluster.name\"], resource.attributes[\"cluster.name\"])","set(attributes[\"trace_id\"], trace_id)","set(attributes[\"span_id\"], span_id)"]}]}},"receivers":{"jaeger":{"protocols":{"grpc":{"endpoint":"0.0.0.0:14250"},"thrift_compact":{"endpoint":"0.0.0.0:6831"},"thrift_http":{"endpoint":"0.0.0.0:14268"}}},"loki":{"protocols":{"grpc":{"endpoint":"0.0.0.0:3600"},"http":{"endpoint":"0.0.0.0:3500","include_metadata":true}},"use_incoming_timestamp":true},"otlp":{"protocols":{"grpc":{"endpoint":"0.0.0.0:4317"},"http":{"endpoint":"0.0.0.0:4318"}}}},"service":{"extensions":["health_check","pprof","zpages"],"pipelines":{"logs":{"exporters":["debug","otlphttp"],"processors":["memory_limiter","resourcedetection","resource","transform","batch"],"receivers":["otlp","loki"]},"metrics":{"exporters":["debug","prometheus"],"processors":["memory_limiter","resourcedetection","resource","metricstransform","batch"],"receivers":["otlp"]},"traces":{"exporters":["debug","otlp/jaeger"],"processors":["memory_limiter","resourcedetection","resource","groupbytrace","batch"],"receivers":["otlp","jaeger"]}},"telemetry":{"logs":{"encoding":"json","level":"debug"},"metrics":{"address":"0.0.0.0:8888","level":"detailed"}}}},"env":[{"name":"K8S_NODE_NAME","valueFrom":{"fieldRef":{"fieldPath":"spec.nodeName"}}},{"name":"K8S_POD_NAME","valueFrom":{"fieldRef":{"fieldPath":"metadata.name"}}},{"name":"K8S_POD_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}},{"name":"K8S_POD_IP","valueFrom":{"fieldRef":{"fieldPath":"status.podIP"}}}],"image":"otel/opentelemetry-collector-contrib:0.128.0","mode":"deployment","replicas":2,"resources":{"limits":{"cpu":"1000m","memory":"1600Mi"},"requests":{"cpu":"500m","memory":"800Mi"}},"serviceAccount":"opentelemetry-collector"}}
  creationTimestamp: "2025-07-15T22:07:42Z"
  finalizers:
  - opentelemetrycollector.opentelemetry.io/finalizer
  generation: 3
  labels:
    app: opentelemetry-collector
    app.kubernetes.io/managed-by: opentelemetry-operator
  name: otelcollector
  namespace: monitoring
  resourceVersion: "376745068"
  uid: 31e845e8-6573-4880-9241-578bbe1bd2af
spec:
  config:
    exporters:
      debug:
        verbosity: basic
      otlp/jaeger:
        endpoint: http://jaeger-collector.monitoring.svc.cluster.local:4317
        headers:
          X-Tenant-ID: default
        tls:
          insecure: true
      otlphttp:
        endpoint: http://loki-write.monitoring.svc.cluster.local:3100/otlp
        headers:
          X-Scope-OrgID: tenant-1
        tls:
          insecure: true
      prometheus:
        const_labels:
          k8s_cluster: clustername
        enable_open_metrics: true
        endpoint: 0.0.0.0:8889
        namespace: monitoring
        send_timestamps: true
    extensions:
      health_check:
        endpoint: 0.0.0.0:13133
        path: /health
      pprof:
        endpoint: 0.0.0.0:1777
      zpages:
        endpoint: 0.0.0.0:55679
    processors:
      batch:
        send_batch_max_size: 4096
        send_batch_size: 1024
        timeout: 200ms
      groupbytrace: {}
      memory_limiter:
        check_interval: 5s
        limit_mib: 512
        limit_percentage: 80
        spike_limit_mib: 64
      metricstransform:
        transforms:
        - action: update
          include: system.cpu.usage
          operations:
          - action: add_label
            new_label: host.name
            new_value: host.name
          - action: add_label
            new_label: cluster.name
            new_value: clustername
        - action: update
          include: system.memory.usage
          operations:
          - action: add_label
            new_label: host.name
            new_value: host.name
          - action: add_label
            new_label: cluster.name
            new_value: clustername
      resource:
        attributes:
        - action: insert
          from_attribute: service.name
          key: service.name
        - action: insert
          from_attribute: k8s.container.name
          key: k8s.container.name
        - action: insert
          from_attribute: k8s.namespace.name
          key: k8s.namespace.name
        - action: insert
          from_attribute: k8s.pod.name
          key: k8s.pod.name
        - action: insert
          from_attribute: k8s.node.name
          key: k8s.node.name
        - action: insert
          from_attribute: host.name
          key: host.name
        - action: upsert
          from_attribute: service.name
          key: service.name
        - action: upsert
          from_attribute: service.namespace
          key: service.namespace
        - action: insert
          key: cluster.name
          value: clustername
      resourcedetection:
        detectors:
        - env
        - system
        - kubernetes
        override: false
        timeout: 2s
      transform:
        log_statements:
        - context: log
          statements:
          - set(attributes["processing.note"], "Log enriched with resource and trace
            context")
          - set(attributes["service.name"], resource.attributes["service.name"])
          - set(attributes["k8s.pod.name"], resource.attributes["k8s.pod.name"])
          - set(attributes["k8s.node.name"], resource.attributes["k8s.node.name"])
          - set(attributes["host.name"], resource.attributes["host.name"])
          - set(attributes["cluster.name"], resource.attributes["cluster.name"])
          - set(attributes["trace_id"], trace_id)
          - set(attributes["span_id"], span_id)
    receivers:
      jaeger:
        protocols:
          grpc:
            endpoint: 0.0.0.0:14250
          thrift_compact:
            endpoint: 0.0.0.0:6831
          thrift_http:
            endpoint: 0.0.0.0:14268
      loki:
        protocols:
          grpc:
            endpoint: 0.0.0.0:3600
          http:
            endpoint: 0.0.0.0:3500
            include_metadata: true
        use_incoming_timestamp: true
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318
    service:
      extensions:
      - health_check
      - pprof
      - zpages
      pipelines:
        logs:
          exporters:
          - debug
          - otlphttp
          processors:
          - memory_limiter
          - resourcedetection
          - resource
          - transform
          - batch
          receivers:
          - otlp
          - loki
        metrics:
          exporters:
          - debug
          - prometheus
          processors:
          - memory_limiter
          - resourcedetection
          - resource
          - metricstransform
          - batch
          receivers:
          - otlp
        traces:
          exporters:
          - debug
          - otlp/jaeger
          processors:
          - memory_limiter
          - resourcedetection
          - resource
          - groupbytrace
          - batch
          receivers:
          - otlp
          - jaeger
      telemetry:
        metrics:
          level: detailed
          readers:
          - pull:
              exporter:
                prometheus:
                  host: 0.0.0.0
                  port: 8888
  configVersions: 3
  daemonSetUpdateStrategy: {}
  deploymentUpdateStrategy: {}
  env:
  - name: K8S_NODE_NAME
    valueFrom:
      fieldRef:
        fieldPath: spec.nodeName
  - name: K8S_POD_NAME
    valueFrom:
      fieldRef:
        fieldPath: metadata.name
  - name: K8S_POD_NAMESPACE
    valueFrom:
      fieldRef:
        fieldPath: metadata.namespace
  - name: K8S_POD_IP
    valueFrom:
      fieldRef:
        fieldPath: status.podIP
  image: otel/opentelemetry-collector-contrib:0.128.0
  ingress:
    route: {}
  ipFamilyPolicy: SingleStack
  managementState: managed
  mode: deployment
  observability:
    metrics: {}
  podDnsConfig: {}
  replicas: 2
  resources:
    limits:
      cpu: "1"
      memory: 1600Mi
    requests:
      cpu: 500m
      memory: 800Mi
  serviceAccount: opentelemetry-collector
  targetAllocator:
    allocationStrategy: consistent-hashing
    collectorNotReadyGracePeriod: 30s
    filterStrategy: relabel-config
    observability:
      metrics: {}
    prometheusCR:
      podMonitorSelector: {}
      scrapeInterval: 30s
      serviceMonitorSelector: {}
    resources: {}
  upgradeStrategy: automatic
status:
  image: otel/opentelemetry-collector-contrib:0.128.0
  scale:
    replicas: 3
    selector: app=opentelemetry-collector,app.kubernetes.io/component=opentelemetry-collector,app.kubernetes.io/instance=monitoring.otelcollector,app.kubernetes.io/managed-by=opentelemetry-operator,app.kubernetes.io/name=otelcollector-collector,app.kubernetes.io/part-of=opentelemetry,app.kubernetes.io/version=0.128.0
    statusReplicas: 0/3
  version: 0.127.0
PS C:\Users\ooridota>



































































































































































kubectl get crds | findstr opentelemetry
instrumentations.opentelemetry.io                            2025-07-09T17:21:21Z
opampbridges.opentelemetry.io                                2025-07-09T17:21:21Z
opentelemetrycollectors.opentelemetry.io                     2025-07-09T17:21:21Z
targetallocators.opentelemetry.io                            2025-07-09T17:21:21Z



Warning  BackOff    51s (x195 over 41m)  kubelet            Back-off restarting failed container otc-container in pod otelcollector-collector









info    service@v0.128.0/service.go:199 Setting up own telemetry...     {"resource": {"service.instance.id": "f372a555-77ee-4647-8083-6bd5c90272b1", "service.name": "otelcol-contrib", "service.version": "0.128.0"}}
2025-07-16T19:17:45.037Z        info    builders/builders.go:26 Development component. May change in the future.        {"resource": {"service.instance.id": "f372a555-77ee-4647-8083-6bd5c90272b1", "service.name": "otelcol-contrib", "service.version": "0.128.0"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "logs"}
2025-07-16T19:17:45.038Z        info    builders/builders.go:26 Development component. May change in the future.        {"resource": {"service.instance.id": "f372a555-77ee-4647-8083-6bd5c90272b1", "service.name": "otelcol-contrib", "service.version": "0.128.0"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "traces"}
2025-07-16T19:17:45.038Z        info    builders/builders.go:26 Development component. May change in the future.        {"resource": {"service.instance.id": "f372a555-77ee-4647-8083-6bd5c90272b1", "service.name": "otelcol-contrib", "service.version": "0.128.0"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
2025-07-16T19:17:45.038Z        error   service@v0.128.0/service.go:189 error found during service initialization       {"resource": {"service.instance.id": "f372a555-77ee-4647-8083-6bd5c90272b1", "service.name": "otelcol-contrib", "service.version": "0.128.0"}, "error": "failed to build pipelines: failed to create \"resourcedetection\" processor, in pipeline \"metrics\": invalid detector key: kubernetes"}
go.opentelemetry.io/collector/service.New.func1
        go.opentelemetry.io/collector/service@v0.128.0/service.go:189
go.opentelemetry.io/collector/service.New
        go.opentelemetry.io/collector/service@v0.128.0/service.go:220
go.opentelemetry.io/collector/otelcol.(*Collector).setupConfigurationComponents
        go.opentelemetry.io/collector/otelcol@v0.128.0/collector.go:197
go.opentelemetry.io/collector/otelcol.(*Collector).Run
        go.opentelemetry.io/collector/otelcol@v0.128.0/collector.go:312
go.opentelemetry.io/collector/otelcol.NewCommand.func1
        go.opentelemetry.io/collector/otelcol@v0.128.0/command.go:39
github.com/spf13/cobra.(*Command).execute
        github.com/spf13/cobra@v1.9.1/command.go:1015
github.com/spf13/cobra.(*Command).ExecuteC
        github.com/spf13/cobra@v1.9.1/command.go:1148
github.com/spf13/cobra.(*Command).Execute
        github.com/spf13/cobra@v1.9.1/command.go:1071
main.runInteractive
        github.com/open-telemetry/opentelemetry-collector-releases/contrib/main.go:70
main.run
        github.com/open-telemetry/opentelemetry-collector-releases/contrib/main_others.go:10
main.main
        github.com/open-telemetry/opentelemetry-collector-releases/contrib/main.go:63
runtime.main
        runtime/proc.go:283
Error: failed to build pipelines: failed to create "resourcedetection" processor, in pipeline "metrics": invalid detector key: kubernetes
2025/07/16 19:17:45 collector server run finished with error: failed to build pipelines: failed to create "resourcedetection" processor, in pipeline "metrics": invalid detector key: kubernetes


apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: opentelemetry-collector
  namespace: monitoring
  labels:
    app: opentelemetry-collector
spec:
  mode: deployment
  image: otel/opentelemetry-collector-contrib:0.128.0
  serviceAccount: opentelemetry-collector
  replicas: 2

  resources:
    requests:
      cpu: 500m
      memory: 800Mi
    limits:
      cpu: 1000m
      memory: 1600Mi

  env:
    - name: K8S_NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    - name: K8S_POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: K8S_POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: K8S_POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP

  config:
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: "0.0.0.0:4317"
          http:
            endpoint: "0.0.0.0:4318"
      jaeger:
        protocols:
          grpc:
            endpoint: "0.0.0.0:14250"
          thrift_http:
            endpoint: "0.0.0.0:14268"
          thrift_compact:
            endpoint: "0.0.0.0:6831"
      loki:
        protocols:
          http:
            endpoint: "0.0.0.0:3500"
            include_metadata: true
          grpc:
            endpoint: "0.0.0.0:3600"
        use_incoming_timestamp: true

    processors:
      batch:
        timeout: 200ms
        send_batch_size: 1024
        send_batch_max_size: 4096
      memory_limiter:
        check_interval: 5s
        limit_percentage: 80
        spike_limit_mib: 64
        limit_mib: 512
      resource:
        attributes:
          - key: service.name
            from_attribute: service.name
            action: upsert
          - key: k8s.container.name
            from_attribute: k8s.container.name
            action: insert
          - key: k8s.namespace.name
            from_attribute: k8s.namespace.name
            action: insert
          - key: k8s.pod.name
            from_attribute: k8s.pod.name
            action: insert
          - key: k8s.node.name
            from_attribute: k8s.node.name
            action: insert
          - key: host.name
            from_attribute: host.name
            action: insert
          - key: service.namespace
            from_attribute: service.namespace
            action: upsert
          - key: cluster.name
            value: "clustername"
            action: insert
      groupbytrace: {}
      transform:
        log_statements:
          - context: log
            statements:
              - set(attributes["processing.note"], "Log enriched with resource and trace context")
              - set(attributes["service.name"], resource.attributes["service.name"])
              - set(attributes["k8s.pod.name"], resource.attributes["k8s.pod.name"])
              - set(attributes["k8s.node.name"], resource.attributes["k8s.node.name"])
              - set(attributes["host.name"], resource.attributes["host.name"])
              - set(attributes["cluster.name"], resource.attributes["cluster.name"])
              - set(attributes["trace_id"], trace_id)
              - set(attributes["span_id"], span_id)
      metricstransform:
        transforms:
          - include: system.cpu.usage
            action: update
            operations:
              - action: add_label
                new_label: host.name
                new_value: host.name
              - action: add_label
                new_label: cluster.name
                new_value: clustername
          - include: system.memory.usage
            action: update
            operations:
              - action: add_label
                new_label: host.name
                new_value: host.name
              - action: add_label
                new_label: cluster.name
                new_value: clustername

    exporters:
      debug:
        verbosity: basic
      otlphttp:
        endpoint: "http://loki-write.monitoring.svc.cluster.local:3100/otlp"
        tls:
          insecure: true
      prometheus:
        endpoint: "0.0.0.0:9464"
        namespace: "monitoring"
        const_labels:
          k8s_cluster: "EDDVAKSCLUS01"
        send_timestamps: true
        enable_open_metrics: true
      otlp/jaeger:
        endpoint: "http://jaeger-collector.monitoring.svc.cluster.local:4317"
        tls:
          insecure: true
        headers:
          "X-Tenant-ID": "default"

    extensions:
      health_check:
        endpoint: "0.0.0.0:13133"
      pprof:
        endpoint: "0.0.0.0:1777"
      zpages:
        endpoint: "0.0.0.0:55679"

    service:
      telemetry:
        metrics:
          level: basic
        logs:
          level: debug
      extensions: [health_check, pprof, zpages]
      pipelines:
        metrics:
          receivers: [otlp]
          processors: [memory_limiter, resource, metricstransform, batch]
          exporters: [debug, prometheus]
        traces:
          receivers: [otlp, jaeger]
          processors: [memory_limiter, resource, groupbytrace, batch]
          exporters: [debug, otlp/jaeger]
        logs:
          receivers: [otlp, loki]
          processors: [memory_limiter, resource, transform, batch]
          exporters: [debug, otlphttp]



We are currently blocked on the ingress controller issue. In the meantime, there’s a pending ticket requesting the AKS inventory for the DEV environment. I’d like to address that while we work on connecting all the pieces for the main issue. We’ve agreed to resume troubleshooting tomorrow."
















######################################################################################################################################################
#######################################################################################################################################################


processors:
  transform:
    log_statements:
      - context: log
        statements:
          - set(attributes["processing.note"], "Log enriched with resource and trace context")
          - set(attributes["service.name"], resource.attributes["service.name"])
          - set(attributes["k8s.pod.name"], resource.attributes["k8s.pod.name"])
          - set(attributes["host.name"], resource.attributes["host.name"])
          - set(attributes["trace_id"], trace_id)
          - set(attributes["span_id"], span_id)




 transform:
    log_statements:
      - context: log
        statements:
          - set(attributes["processing.note"], "Log enriched with span context")
          - set(attributes["service.name"], resource.attributes["service.name"])
          - set(attributes["k8s.pod"], resource.attributes["k8s.pod.name"])
          - merge_maps(attributes, resource.attributes, "insert")
          - merge_maps(attributes, span.attributes, "insert")

  # Metric transformations (optional)
  metricstransform:
    transforms:
      - include: system.cpu.usage
        action: update
        operations:
          - action: add_label
            new_label: host.name
            new_value: host.name
      - include: system.memory.usage
        action: update
        operations:
          - action: add_label
            new_label: host.name
            new_value: host.name

           

 












# grafana-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: grafana-ingress
  namespace: your-namespace
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /$1  # Simple rewrite
    nginx.ingress.kubernetes.io/app-root: /grafana/  # Redirects /grafana to /grafana/
spec:
  rules:
  - http:
      paths:
      - path: /grafana(/|$)(.*)
        pathType: ImplementationSpecific
        backend:
          service:
            name: grafana-proxy  # Points to ExternalName service
            port:
              number: 3000



prometheus:
  additionalServiceMonitors:
    - name: otel-collector-monitor
      selector:
        matchLabels:
          app.kubernetes.io/name: opentelemetry-collector
      namespaceSelector:
        matchNames:
          - monitoring
      endpoints:
        - port: prometheus
          interval: 10s
          path: /metrics







# OpenTelemetry Collector Helm Values Configuration
# Deploy with: helm upgrade --install otel-collector open-telemetry/opentelemetry-collector -f values.yaml -n monitoring

mode: "deployment"
nameOverride: "opentelemetry-collector"
fullnameOverride: "opentelemetry-collector"
replicaCount: 2

configMap:
  create: true

image:
  repository: "otel/opentelemetry-collector-contrib"  # Using contrib for more processors
  pullPolicy: IfNotPresent
  tag: "0.96.0"  # Using a stable version

resources:
  requests:
    cpu: 500m
    memory: 800Mi
  limits:
    cpu: 1000m
    memory: 1600Mi

serviceAccount:
  create: true

config:
  receivers:
    otlp:
      protocols:
        grpc:
          endpoint: 0.0.0.0:4317
        http:
          endpoint: 0.0.0.0:4318

  processors:
    batch:
      timeout: 200ms
      send_batch_size: 1024
      send_batch_max_size: 4096
    memory_limiter:
      check_interval: 5s
      limit_percentage: 80
      spike_limit_mib: 64
      limit_mib: 512

  exporters:
    debug:
      verbosity: basic
    prometheus:
      endpoint: "0.0.0.0:8889"
      namespace: "monitoring"
      const_labels:
        k8s_cluster: "EDDVAKSCLUS01"
      send_timestamps: true
      enable_open_metrics: true

  extensions:
    health_check:
      endpoint: 0.0.0.0:13133

  service:
    telemetry:
      logs:
        level: debug
    extensions: [health_check]
    pipelines:
      metrics:
        receivers: [otlp]
        processors: [memory_limiter, batch]
        exporters: [debug, prometheus]

service:
  ports:
    otlp-grpc:
      enabled: true
      port: 4317
    otlp-http:
      enabled: true
      port: 4318
    prometheus:
      enabled: true
      port: 8889

livenessProbe:
  httpGet:
    path: /
    port: 13133
  initialDelaySeconds: 15
  periodSeconds: 20
  timeoutSeconds: 5
  failureThreshold: 3

readinessProbe:
  httpGet:
    path: /
    port: 13133
  initialDelaySeconds: 5
  periodSeconds: 10
  timeoutSeconds: 3
  failureThreshold: 3

autoscaling:
  enabled: true
  minReplicas: 2
  maxReplicas: 7
  targetCPUUtilizationPercentage: 90
  targetMemoryUtilizationPercentage: 90




########
update



