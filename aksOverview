---
# ServiceAccount for OpenTelemetry Collector
apiVersion: v1
kind: ServiceAccount
metadata:
  name: opentelemetry-collector
  namespace: monitoring
  labels:
    app: opentelemetry-collector
---
# ClusterRole for OpenTelemetry Collector ServiceAccount
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: opentelemetry-collector
rules:
  - apiGroups: [""]
    resources: ["pods", "namespaces", "nodes"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["apps"]
    resources: ["replicasets"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["extensions"]
    resources: ["replicasets"]
    verbs: ["get", "list", "watch"]
---
# ClusterRoleBinding for OpenTelemetry Collector ServiceAccount
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: opentelemetry-collector
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: opentelemetry-collector
subjects:
  - kind: ServiceAccount
    name: opentelemetry-collector
    namespace: monitoring
---
# OpenTelemetry Operator configuration
manager:
  image:
    repository: otel/opentelemetry-operator
    tag: v0.127.0

rbac:
  create: true
---
# Additional ClusterRole for OpenTelemetry Operator
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: otel-operator-extra
rules:
  - apiGroups: ["opentelemetry.io"]
    resources: ["targetallocators"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["monitoring.coreos.com"]
    resources: ["servicemonitors", "podmonitors"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["policy"]
    resources: ["poddisruptionbudgets"]
    verbs: ["get", "list", "watch"]
---
# ClusterRoleBinding for OpenTelemetry Operator extra permissions
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: otel-operator-extra-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: otel-operator-extra
subjects:
  - kind: ServiceAccount
    name: opentelemetry-operator
    namespace: monitoring
---
# OpenTelemetry Collector Custom Resource
apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: otelcollector
  namespace: monitoring
  labels:
    app: opentelemetry-collector
spec:
  mode: deployment
  replicas: 2
  image: otel/opentelemetry-collector-contrib:0.128.0
  serviceAccount: opentelemetry-collector

  resources:
    requests:
      cpu: 500m
      memory: 800Mi
    limits:
      cpu: 1000m
      memory: 1600Mi

  env:
    - name: K8S_NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    - name: K8S_POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: K8S_POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: K8S_POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP

  config: |
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: "0.0.0.0:4317"
          http:
            endpoint: "0.0.0.0:4318"
      jaeger:
        protocols:
          grpc:
            endpoint: "0.0.0.0:14250"
          thrift_http:
            endpoint: "0.0.0.0:14268"
          thrift_compact:
            endpoint: "0.0.0.0:6831"
      loki:
        protocols:
          http:
            endpoint: "0.0.0.0:3500"
            include_metadata: true
          grpc:
            endpoint: "0.0.0.0:3600"
        use_incoming_timestamp: true

    processors:
      batch:
        timeout: 200ms
        send_batch_size: 1024
        send_batch_max_size: 4096
      memory_limiter:
        check_interval: 5s
        limit_percentage: 80
        spike_limit_mib: 64
        limit_mib: 512
      resourcedetection:
        detectors: ["env", "system", "kubernetes"]
        timeout: 2s
        override: false
      resource:
        attributes:
          - key: service.name
            from_attribute: service.name
            action: insert
          - key: k8s.container.name
            from_attribute: k8s.container.name
            action: insert
          - key: k8s.namespace.name
            from_attribute: k8s.namespace.name
            action: insert
          - key: k8s.pod.name
            from_attribute: k8s.pod.name
            action: insert
          - key: k8s.node.name
            from_attribute: k8s.node.name
            action: insert
          - key: host.name
            from_attribute: host.name
            action: insert
          - key: service.name
            from_attribute: service.name
            action: upsert
          - key: service.namespace
            from_attribute: service.namespace
            action: upsert
          - key: cluster.name
            value: "clustername"
            action: insert
      groupbytrace: {}
      transform:
        log_statements:
          - context: log
            statements:
              - set(attributes["processing.note"], "Log enriched with resource and trace context")
              - set(attributes["service.name"], resource.attributes["service.name"])
              - set(attributes["k8s.pod.name"], resource.attributes["k8s.pod.name"])
              - set(attributes["k8s.node.name"], resource.attributes["k8s.node.name"])
              - set(attributes["host.name"], resource.attributes["host.name"])
              - set(attributes["cluster.name"], resource.attributes["cluster.name"])
              - set(attributes["trace_id"], trace_id)
              - set(attributes["span_id"], span_id)
      metricstransform:
        transforms:
          - include: system.cpu.usage
            action: update
            operations:
              - action: add_label
                new_label: host.name
                new_value: host.name
              - action: add_label
                new_label: cluster.name
                new_value: clustername
          - include: system.memory.usage
            action: update
            operations:
              - action: add_label
                new_label: host.name
                new_value: host.name
              - action: add_label
                new_label: cluster.name
                new_value: clustername

    exporters:
      debug:
        verbosity: basic
      otlphttp:
        endpoint: "http://loki-write.monitoring.svc.cluster.local:3100/otlp"
        tls:
          insecure: true
        headers:
          "X-Scope-OrgID": "tenant-1"
      prometheus:
        endpoint: "0.0.0.0:8889"
        namespace: "monitoring"
        const_labels:
          k8s_cluster: "clustername"
        send_timestamps: true
        enable_open_metrics: true
      otlp/jaeger:
        endpoint: "http://jaeger-collector.monitoring.svc.cluster.local:4317"
        tls:
          insecure: true
        headers:
          "X-Tenant-ID": "default"

    extensions:
      health_check:
        endpoint: "0.0.0.0:13133"
        path: "/health"
      pprof:
        endpoint: "0.0.0.0:1777"
      zpages:
        endpoint: "0.0.0.0:55679"

    service:
      telemetry:
        logs:
          level: debug
          encoding: json
        metrics:
          level: detailed
          address: "0.0.0.0:8888"
      extensions: [health_check, pprof, zpages]
      pipelines:
        metrics:
          receivers: [otlp]
          processors: [memory_limiter, resourcedetection, resource, metricstransform, batch]
          exporters: [debug, prometheus]
        traces:
          receivers: [otlp, jaeger]
          processors: [memory_limiter, resourcedetection, resource, groupbytrace, batch]
          exporters: [debug, otlp/jaeger]
        logs:
          receivers: [otlp, loki]
          processors: [memory_limiter, resourcedetection, resource, transform, batch]
          exporters: [debug, otlphttp]

  ports:
    - name: otlp-grpc
      port: 4317
      targetPort: 4317
      protocol: TCP
    - name: otlp-http
      port: 4318
      targetPort: 4318
      protocol: TCP
    - name: jaeger-compact
      port: 6831
      targetPort: 6831
      protocol: UDP
    - name: jaeger-thrift
      port: 14268
      targetPort: 14268
      protocol: TCP
    - name: jaeger-grpc
      port: 14250
      targetPort: 14250
      protocol: TCP
    - name: metrics
      port: 8888
      targetPort: 8888
      protocol: TCP
    - name: prometheus
      port: 8889
      targetPort: 8889
      protocol: TCP
    - name: loki-http
      port: 3500
      targetPort: 3500
      protocol: TCP
    - name: loki-grpc
      port: 3600
      targetPort: 3600
      protocol: TCP
    - name: health-check
      port: 13133
      targetPort: 13133
      protocol: TCP
    - name: pprof
      port: 1777
      targetPort: 1777
      protocol: TCP
    - name: zpages
      port: 55679
      targetPort: 55679
      protocol: TCP

  podDisruptionBudget:
    maxUnavailable: 1

  autoscaler:
    minReplicas: 2
    maxReplicas: 5
    targetCPUUtilization: 80
    targetMemoryUtilization: 80

  securityContext:
    runAsNonRoot: true
    runAsUser: 65534
    fsGroup: 65534

  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault

  volumeMounts:
    - name: tmp
      mountPath: /tmp

  volumes:
    - name: tmp
      emptyDir: {}

  tolerations:
    - key: "node.kubernetes.io/not-ready"
      operator: "Exists"
      effect: "NoExecute"
      tolerationSeconds: 300
    - key: "node.kubernetes.io/unreachable"
      operator: "Exists"
      effect: "NoExecute"
      tolerationSeconds: 300

  nodeSelector:
    kubernetes.io/os: linux
