Apps & PaaS → Opentelemetry AutoInstrumentation(Optional)  → VM OTel Collector (gateway)
    → Prometheus (metrics) → Grafana
    → Loki (logs)          → Grafana
    → Jaeger (traces)      → Grafana
Components
Azure VM (Obs Gateway & Backends):
OTel Collector (gateway)
Prometheus (scrape & remote_write endpoints)
Loki (log ingestion)
Jaeger (collector + query + UI)
Grafana (dashboards/alerts)
In Cluster: OpenTelemetry AutoInstrumentation CRD ( Autoinstrumentation injection for node/app scraping/export).



















What We Install on the VM
The dedicated VM runs the entire observability stack via Docker:
Installed Components (Docker Containers)
Component	Role	Data Type	Port
OpenTelemetry Collector	Central telemetry receiver	Logs/Metrics/Traces	4317, 4318
Loki	Log aggregation & storage	Logs	3100
Prometheus	Metrics scraping & storage	Metrics	9090
Jaeger	Distributed tracing	Traces	14268, 16686
Grafana	Dashboards & visualization	UI	3000
Configuration Files
•	otel-collector-config.yaml (Routes telemetry to Loki/Prometheus/Jaeger)
•	prometheus.yml (Defines scrape targets in AKS)
•	loki-config.yaml (Log retention, storage settings)
•	grafana-datasources.yaml (Pre-configures Loki/Prometheus as data sources)


High-Level Flow details
------------------------------
AKS Applications generate telemetry (instrumented via OpenTelemetry SDKs or sidecars).

OTel Collector (Sidecar in AKS) collects and forwards data to the VM’s OTel Collector.

VM OTel Collector distributes data:

Metrics → Prometheus (scraped or pushed)

Logs → Loki (HTTP push)

Traces → Jaeger (gRPC push)

Grafana queries all backends (Loki, Prometheus, Jaeger) for visualization.























o	How data is pulled or pushed between the VM and AKS
o	What exactly do we install on the VM and AKS
o	Visualize the network planes in those data flows to ensure things like firewalls nsg's etc. don't become hurdles during implementation
o	How do we secure the flow (mTLS, authentication, etc.)

Environmental constraints have redirected OSS observability priorities, leading to the closure of this story



error: Error: failed to perform "FetchReference" on source: from ACR after it confirned it has been pushed to the ACR

apiVersion: v2
name: prom-operator-crds-bootstrap
description: Installs Prometheus Operator CRDs (v0.83.0) via dependency chart
type: application
version: 1.0.0
appVersion: "0.83.0"

dependencies:
  - name: prometheus-operator-crds
    alias: promOperatorCRDs
    version: 22.0.2
    repository: oci://private-registry.azurecr.io/
    condition: promOperatorCRDs.enabled

# values.yaml
promOperatorCRDs:
  enabled: true






#source.yaml
apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: HelmRepository
metadata:
  name: prometheus-community
  labels:
     repoName: prometheus
#  namespace: monitoring
spec:
  url: https://prometheus-community.github.io/helm-charts
  interval: 1h


# url: https://prometheus-community.github.io/helm-charts
# repoName: prometheus

#chart.yaml 

---
apiVersion: v2
name: prometheus
description: Prometheus metrics data source for observability
type: application
version: 1.0.0
appVersion: "1.0.0"

dependencies:
  - name: prometheus
    version: 27.23.0
    repository: oci://private-registry.azurecr.io/hbt/charts
  - name: alertmanager
    version: 1.22.0
    repository: oci://private-registry.azurecr.io/hbt/charts

---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: prom-operator-crds
#  namespace: monitoring
spec:
  interval: 30m
  chart:
    spec:
      chart: prometheus-operator-crds
      version: 22.0.2          
      sourceRef:
        kind: HelmRepository
        name: prometheus-community
#        namespace: monitoring
  install:
    crds: Create
  upgrade:
    crds: CreateReplace


