###########################################################################################


# OpenTelemetry Collector Helm Values Configuration
# Deploy with: helm install otel-collector open-telemetry/opentelemetry-collector -f values.yaml

mode: "deployment"
nameOverride: "opentelemetry-collector"
fullnameOverride: "opentelemetry-collector"
replicaCount: 2

configMap:
  create: true
  existingName: ""

internalTelemetryViaOTLP:
  endpoint: ""
  headers: []
  traces:
    enabled: false
  metrics:
    enabled: false
  logs:
    enabled: false

config:
  receivers:
    otlp:
      protocols:
        grpc:
          endpoint: 0.0.0.0:4317
        http:
          endpoint: 0.0.0.0:4318
    jaeger:
      protocols:
        grpc:
          endpoint: 0.0.0.0:14250
        thrift_http:
          endpoint: 0.0.0.0:14268
        thrift_compact:
          endpoint: 0.0.0.0:6831
    # kubeletstats:
    #   insecure_skip_verify: true
    # prometheus:
    #   config:
    #     scrape_configs:
    #       - job_name: opentelemetry-collector
    #         scrape_interval: 10s
    #         static_configs:
    #           - targets:
    #             - 0.0.0.0:8888 

    prometheus:
      config:
        scrape_configs:
          - job_name: "otentelemetry-collector"
            scrape_interval: 10s
            static_configs:
              - targets: ["${env:POD_IP}:8888"]
            relabel_configs:
              - source_labels: [__address__]
                target_label: __tmp_hash
                modulus: 1
                action: hashmod
              - source_labels: [__tmp_hash]
                regex: "0"
                action: keep

  processors:
    batch: 
      timeout: 200ms
      send_batch_size: 1024 
      send_batch_max_size: 4096
    # transform:
    #   error_mode: ignore
    #   log_statements:
    #     - context: log
    #       statements: 
    #         - set(resource.attributes["service.name"], attributes["service_name"])
    #         - delete_key(attributes, "service_name")
    # Uncomment and configure memory limiter if needed
    memory_limiter:
      check_interval: 5s
      limit_percentage: 80
      spike_limit_mib: 64
      limit_mib: 512

  exporters:
    debug: 
      verbosity: basic
    otlphttp:
      endpoint: "http://loki-write.monitoring.svc.cluster.local:3100/otlp"
      tls:
        insecure: true
    prometheus:
      endpoint: "0.0.0.0:8889"
    otlp:
      endpoint: "http://jaeger-collector.monitoring.svc.cluster.local:4317"
      tls:
        insecure: true
    # Named OTLP exporter for Jaeger
    otlp/jaeger:
      endpoint: "http://jaeger-collector.monitoring.svc.cluster.local:4317"
      tls:
        insecure: true
  
  extensions:
    health_check:
      endpoint: 0.0.0.0:13133

  service:
    telemetry:
      logs: 
        level: debug
    extensions:
      - health_check
    pipelines: 
      metrics:
        receivers: [otlp, prometheus]
        processors: [memory_limiter, batch]
        exporters: [debug, prometheus]
      traces:
        receivers: [otlp, jaeger]
        processors: [batch, memory_limiter]
        exporters: [debug, otlp/jaeger]
      logs:
        receivers: [otlp]
        processors: [memory_limiter, batch]
        exporters: [debug, otlphttp]

image:
  repository: "otel/opentelemetry-collector"
  pullPolicy: IfNotPresent
  tag: "0.123.0"

resources:
  requests:
    cpu: 500m
    memory: 800Mi
  limits:
    cpu: 1000m
    memory: 1600Mi

serviceAccount:
  create: true

ports:
  otlp:
    enabled: true
    containerPort: 4317
    servicePort: 4317
    hostPort: 4317
  otlp-http:
    enabled: true
    containerPort: 4318
    servicePort: 4318
  jaeger-compact:
    enabled: true
    containerPort: 6831
    protocol: UDP
  jaeger-thrift:
    enabled: true
    containerPort: 14268
  jaeger-grpc:
    enabled: true
    containerPort: 14250
  metrics:
    enabled: true
    containerPort: 8888
    servicePort: 8888
    hostPort: 8888
    protocol: TCP 
  prometheus:
    enabled: true
    containerPort: 8889
    servicePort: 8889
    hostPort: 8889
    protocol: TCP 

extraEnvs:
  - name: POD_IP
    valueFrom:
      fieldRef:
        fieldPath: status.podIP

livenessProbe:
  httpGet:
    path: /
    port: 13133
  initialDelaySeconds: 15
  periodSeconds: 20
  timeoutSeconds: 5
  failureThreshold: 3

readinessProbe:
  httpGet:
    path: /
    port: 13133
  initialDelaySeconds: 5
  periodSeconds: 10
  timeoutSeconds: 3
  failureThreshold: 3

autoscaling:
  enabled: true
  minReplicas: 2
  maxReplicas: 7
  targetCPUUtilizationPercentage: 90
  targetMemoryUtilizationPercentage: 90

useGOMEMLIMIT: true












#######################################################################################
grafana:
  enabled: false

installCRDs: true

prometheus:
  prometheusSpec:
    additionalScrapeConfigs:
      - job_name: "otel-collector"
        scrape_interval: 10s
        static_configs:
          - targets: ["otel-collector:9464"]
        metrics_path: "/metrics"
        honor_labels: true








- task: HelmDeploy@0
  displayName: 'Deploy kube-prometheus-stack with OTEL Collector scraping'
  inputs:
    azureSubscription: $(azureSubscription)
    command: 'upgrade'
    chartType: 'Name'
    chartName: 'prometheus-community/kube-prometheus-stack'
    chartVersion: 'latest'
    kubernetesCluster: $(clusterName)
    azureResourceGroup: $(resourceGroup)
    namespace: $(k8sNamespace)
    releaseName: 'kube-prometheus-stack'
    install: true
    waitForExecution: true
    arguments: |
      --timeout 5m0s 
      --create-namespace 
      --set grafana.enabled=false 
      --set installCRDs=true
      --set prometheus.prometheusSpec.additionalScrapeConfigs[0].job_name=otel-collector
      --set prometheus.prometheusSpec.additionalScrapeConfigs[0].scrape_interval=10s
      --set prometheus.prometheusSpec.additionalScrapeConfigs[0].static_configs[0].targets[0]="otel-collector:9464"
      --set prometheus.prometheusSpec.additionalScrapeConfigs[0].metrics_path=/metrics
      --set prometheus.prometheusSpec.additionalScrapeConfigs[0].honor_labels=true

####################



# prometheus/values.yaml
server:
  global:
    scrape_interval: 15s

extraScrapeConfigs:
  - job_name: 'otel-collector'
    scrape_interval: 10s
    static_configs:
      - targets: ['otel-collector:9464']
    metrics_path: '/metrics'
    honor_labels: true

# otel-collector/templates/servicemonitor.yaml
    apiVersion: monitoring.coreos.com/v1
    kind: ServiceMonitor
    metadata:
      name: otel-collector
      labels:
        release: prometheus
    spec:
      endpoints:
        - port: metrics
          interval: 10s
          path: /metrics
      selector:
        matchLabels:
          app.kubernetes.io/instance: otel-collector





##########
# values.yaml
mode: "deployment"

nameOverride: "opentelemetry-collector"
fullnameOverride: "opentelemetry-collector"

replicaCount: 2

config:
  receivers:
    otlp:
      protocols:
        grpc:
          endpoint: 0.0.0.0:4317
        http:
          endpoint: 0.0.0.0:4318
    prometheus:
      config:
        scrape_configs:
          - job_name: "otel-collector-metrics"
            scrape_interval: 10s
            static_configs:
              - targets: ["${env:POD_IP}:8888"]
            relabel_configs:
              - source_labels: [__address__]
                target_label: __tmp_hash
                modulus: 1
                action: hashmod
              - source_labels: [__tmp_hash]
                regex: "0"
                action: keep

  processors:
    batch:
      timeout: 10s
      send_batch_size: 1000

  exporters:
    debug:
      verbosity: detailed
    prometheus:
      endpoint: "0.0.0.0:8889"

  service:
    pipelines:
      metrics:
        receivers: [prometheus, otlp]
        processors: [batch]
        exporters: [debug, prometheus]
      traces:
        receivers: [otlp]
        processors: [batch]
        exporters: [debug]

image:
  repository: "otel/opentelemetry-collector"
  pullPolicy: IfNotPresent
  tag: "0.123.0"

resources:
  requests:
    cpu: 500m
    memory: 800Mi
  limits:
    cpu: 1000m
    memory: 1600Mi

serviceAccount:
  create: true

ports:
  metrics:
    enabled: true
    containerPort: 8888
    servicePort: 8888
    protocol: TCP
  prometheus:
    enabled: true
    containerPort: 8889
    servicePort: 8889
    protocol: TCP

env:
  - name: POD_IP
    valueFrom:
      fieldRef:
        fieldPath: status.podIP

livenessProbe:
  httpGet:
    path: /
    port: 13133
  initialDelaySeconds: 15
  periodSeconds: 20

readinessProbe:
  httpGet:
    path: /
    port: 13133
  initialDelaySeconds: 5
  periodSeconds: 10







#####################

debug Scrape failed {"scrape_pool": "opentelemetry-collector", "target": "http://0.0.0.0:8888/metrics", "err": "Get \"http://0.0.0.0:8888/metrics\": dial tcp 0.0.0.0:8888: connect: connection refused"}

warn internal/transaction.go:137 Failed to scrape Prometheus endpoint {"scrape_timestamp": 1751995973625, "target_labels": "{__name__=\"up\", instance=\"0.0.0.0:8888\", job=\"opentelemetry-collector\"}"}

########
service:
    telemetry:
      logs: 
        level: debug
    extensions:
      - health_check
    pipelines: 
      metrics:
        receivers: [otlp, prometheus]
        processors: [batch]
        exporters: [debug, prometheus]
      traces:
        receivers: [otlp, jaeger]
        processors: [batch]
        exporters: [debug, otlp]


##################################









# OpenTelemetry Collector Helm Values Configuration
# Deploy with: helm install otel-collector open-telemetry/opentelemetry-collector -f values.yaml

mode: "deployment"
nameOverride: "opentelemetry-collector"
fullnameOverride: "opentelemetry-collector"
replicaCount: 2

configMap:
  create: true
  existingName: ""

internalTelemetryViaOTLP:
  endpoint: ""
  headers: []
  traces:
    enabled: false
  metrics:
    enabled: false
  logs:
    enabled: false

config:
  receivers:
    otlp:
      protocols:
        grpc:
          endpoint: 0.0.0.0:4317
        http:
          endpoint: 0.0.0.0:4318
    jaeger:
      protocols:
        grpc:
          endpoint: 0.0.0.0:14250
        thrift_http:
          endpoint: 0.0.0.0:14268
        thrift_compact:
          endpoint: 0.0.0.0:6831
    kubeletstats:
      insecure_skip_verify: true
    prometheus:
      config:
        scrape_configs:
          - job_name: opentelemetry-collector
            scrape_interval: 10s
            static_configs:
              - targets:
                - 0.0.0.0:8888

  processors:
    batch: 
      timeout: 10s
      send_batch_size: 1000 
      send_batch_max_size: 5000
    transform:
      error_mode: ignore
      log_statements:
        - context: log
          statements: 
            - set(resource.attributes["service.name"], attributes["service_name"])
            - delete_key(attributes, "service_name")
    # Uncomment and configure memory limiter if needed
    # memory_limiter:
    #   check_interval: 5s
    #   limit_percentage: 80
    #   spike_limit_percentage: 25

  exporters:
    debug: 
      verbosity: basic
    otlphttp:
      endpoint: "http://loki-gateway.monitoring.svc.cluster.local:3100/loki/api/v1/push"
      tls:
        insecure: true
    prometheus:
      endpoint: "0.0.0.0:8889"
    otlp:
      endpoint: jaeger-collector:4317
      tls:
        insecure: true
    # Named OTLP exporter for Jaeger
    otlp/jaeger:
      endpoint: jaeger-collector:4317
      tls:
        insecure: true

  extensions:
    health_check:
      endpoint: 0.0.0.0:13133

  service:
    telemetry:
      logs: 
        level: debug
      metrics:
        readers:
          - pull:
              exporter:
                prometheus:
                  host: 0.0.0.0
                  port: 8888
    extensions:
      - health_check
    pipelines: 
      logs:
        receivers: [otlp]
        processors: [transform, batch]
        exporters: [debug, otlphttp]
      metrics:
        receivers: [otlp, prometheus]
        processors: [transform, batch]
        exporters: [debug, prometheus]
      traces:
        receivers: [otlp]
        processors: [batch]
        exporters: [debug, otlp/jaeger]

image:
  repository: "otel/opentelemetry-collector-contrib"
  pullPolicy: IfNotPresent
  tag: "0.123.0"

resources:
  requests:
    cpu: 500m
    memory: 800Mi
  limits:
    cpu: 1000m
    memory: 1600Mi

serviceAccount:
  create: true

ports:
  otlp:
    enabled: true
    containerPort: 4317
    servicePort: 4317
    hostPort: 4317
  otlp-http:
    enabled: true
    containerPort: 4318
    servicePort: 4318
  jaeger-compact:
    enabled: true
    containerPort: 6831
    protocol: UDP
  jaeger-thrift:
    enabled: true
    containerPort: 14268
  jaeger-grpc:
    enabled: true
    containerPort: 14250
  metrics:
    enabled: true
    containerPort: 8888
    servicePort: 8888
    hostPort: 8888
    protocol: TCP 
  prometheus:
    enabled: true
    containerPort: 8889
    servicePort: 8889
    hostPort: 8889
    protocol: TCP 

livenessProbe:
  httpGet:
    path: /
    port: 13133

readinessProbe:
  httpGet:
    path: /
    port: 13133
  initialDelaySeconds: 5
  periodSeconds: 10

useGOMEMLIMIT: true
