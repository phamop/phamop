## Title  
Dev: Implement Permanent AKS-hosted OSS Observability Stack

## 1. Description  
- **Problem/Need:**  
  Implement the approved design to deploy a permanent, dedicated OSS observability stack (Grafana, Prometheus, Loki, Jaeger) directly on AKS and wire AKS telemetry via OpenTelemetry Collector, without changing existing AKS/APIM ingress configuration.

- **Expected Outcome:**  
  Working deployment on dedicated AKS cluster using Helm charts and Kustomize overlays, with network-only access, configurable retention policies, and comprehensive runbook. Telemetry from application workloads is visible end-to-end with proper resource isolation and scalability.

- **Related Links:**  
  - (Link to the approved design story)

## 2. Implementation Approach  
- **Key Steps:**  
  - Create dedicated AKS namespace with appropriate resource quotas and network policies for observability stack isolation.
  - Deploy Helm charts for core observability components (Grafana, Prometheus Operator, Loki, Jaeger) with custom values files.
  - Use Kustomize overlays to manage environment-specific configurations and resource customizations.
  - Configure OpenTelemetry Collector as DaemonSet to collect metrics, logs, and traces from AKS nodes and forward to observability stack.
  - Set up Prometheus ServiceMonitors and PodMonitors for application workload discovery and scraping.
  - Configure Grafana data sources, dashboards, and alerting rules using Kubernetes ConfigMaps and Secrets.
  - Implement RBAC policies, service accounts, and disable anonymous access with proper authentication mechanisms.
  - Configure retention policies in Prometheus and Loki per storage and compliance requirements.
  - Set up persistent volumes with appropriate storage classes for data persistence.
  - Validate telemetry flow, dashboard functionality, and alerting; create comprehensive runbook covering deployment, scaling, backup, and troubleshooting procedures.
  - Version Helm values, Kustomize overlays, and configuration files in GitOps-ready repository structure.

- **Technical Considerations:**  
  - Use Helm chart dependencies and sub-charts for modular component management
  - Implement Kustomize patches for environment-specific resource limits and configurations
  - Configure horizontal pod autoscaling for Grafana and collector components
  - Set up network policies to restrict inter-pod communication to required services only
  - Use Kubernetes secrets for sensitive configuration data and credentials

## 3. Value & Priority  
- **Impact:**  
  Establishes production-grade developer observability with native Kubernetes integration, horizontal scalability, and maintainable configuration management. Provides foundation for advanced monitoring capabilities and compliance requirements.












Of course. Here is the redefined content, shifting the focus from a temporary VM to a dedicated, permanent AKS-based solution while maintaining the use of Helm and Kustomize and explicitly excluding GitOps.

***

## **Title**
**Dev: Implement Permanent AKS-Hosted OSS Observability Stack**

## **1. Description**
- **Problem/Need:**
  Implement a permanent, highly available observability stack (Grafana, Prometheus, Loki, Jaeger) hosted *within* the AKS cluster itself. The stack will be isolated in a dedicated namespace and will consume AKS application telemetry via OpenTelemetry Collector, without changing AKS/APIM ingress.

- **Expected Outcome:**
  A robust, persistent deployment on AKS using Helm and Kustomize for management. The solution will include secure access, defined data retention policies, and a comprehensive runbook. End-to-end telemetry from AKS applications will be visible.

- **Related Links:**
  - (Link to the approved design story)

## **2. Implementation Approach**
- **Key Steps:**
  1.  **Namespace Isolation:** Create a dedicated namespace (e.g., `monitoring`) to isolate all observability resources.
  2.  **Helm-Based Deployment:** Use Helm charts to deploy the core components:
      - **Prometheus:** Deploy the [Prometheus Community Helm Chart](https://github.com/prometheus-community/helm-charts) with persistent volume claims (PVCs) for data storage and remote write enabled to receive data from Otel Collector.
      - **Loki:** Deploy the [Grafana Loki Helm Chart](https://github.com/grafana/helm-charts/tree/main/charts/loki) with PVCs for durable log storage.
      - **Jaeger:** Deploy the [Jaeger Operator Helm Chart](https://github.com/jaegertracing/helm-charts) to manage Jaeger instances.
      - **Grafana:** Deploy the [Grafana Helm Chart](https://github.com/grafana/helm-charts/tree/main/charts/grafana). Pre-configure datasources (Prometheus, Loki, Jaeger) using Helm values or init containers.
  3.  **Configuration Management:** Use Kustomize to manage environment-specific overrides (e.g., ingress hosts, resource limits, retention periods) for the Helm chart values, ensuring consistency across environments.
  4.  **OpenTelemetry Collector Configuration:** Deploy the OpenTelemetry Collector as a DaemonSet or Deployment within AKS. Configure it to:
      - **Metrics:** Remote write to the in-cluster Prometheus service.
      - **Logs:** Export via HTTP to the in-cluster Loki service.
      - **Traces:** Export via OTLP to the in-cluster Jaeger collector service.
  5.  **Security & Access Control:**
      - Apply Kubernetes Network Policies to restrict traffic to the observability namespace.
      - Configure Grafana authentication (e.g., integrate with existing OAuth provider).
      - Utilize Kubernetes Secrets managed by Kustomize for sensitive data (passwords, API keys).
  6.  **Persistence & Retention:** Define and configure PersistentVolumeClaims (PVCs) via the Helm charts to ensure data persistence across pod restarts. Set data retention policies explicitly in Prometheus and Loki configuration.
  7.  **Validation & Documentation:** Validate the full telemetry pipeline. Create a detailed runbook for operational tasks (e.g., restarting components, checking pod logs, scaling, backup procedures) and troubleshooting.

## **3. Value & Priority**
- **Impact:**
  **Permanent Solution:** Provides a stable, scalable, and maintainable observability platform integrated directly into the Kubernetes ecosystem.
  **High Availability:** Leverages Kubernetes' scheduling and self-healing capabilities for higher reliability than a single VM.
  **Reduced Operational Overhead:** Eliminates the need to manage a separate VM (patching, backups, OS maintenance).
  **Superior Integration:** Native Kubernetes service discovery for Prometheus scraping simplifies configuration.
  **Clear Ownership:** The stack is managed as code (Helm/Kustomize) within the cluster, making it easier to version, audit, and manage its lifecycle.











## Title  
Dev: Implement Temporary VM-hosted OSS Observability Stack

## 1. Description  
- **Problem/Need:**  
  Implement the approved design to deploy a temporary, private VM-hosted OSS observability stack (Grafana, Prometheus, Loki, Jaeger) and wire AKS telemetry via OpenTelemetry Collector, without changing AKS/APIM ingress.

- **Expected Outcome:**  
  Working deployment on a Linux VM using Docker Compose and Ansible, with existing network-only access, short retention, and a brief runbook. Telemetry from AKS is visible end-to-end.

- **Related Links:**  
  - (Link to the approved design story)

## 2. Implementation Approach  
- **Key Steps:**  
  - Provision VM in the existing subnet; apply firewall/NSG rules for local-only access.  
  - Use Ansible to install Docker, deploy Docker Compose stack (Grafana, Prometheus with remote write receiver, Loki, Jaeger), configure restart policies.  
  - Configure OpenTelemetry Collector in AKS to forward metrics (remote write), logs (Loki HTTP), and traces (OTLP) to the VM.  
  - Apply credentials, RBAC, and disable anonymous access; set retention in Prometheus/Loki per design.  
  - Validate telemetry flow and UI access; create a short runbook for common tasks and troubleshooting.  
  - Version compose files and Ansible playbooks in the repo; record decommission/sunset steps.

## 3. Value & Priority  
- **Impact:**  
  Restores developer observability rapidly with minimal risk and clear rollback path.





