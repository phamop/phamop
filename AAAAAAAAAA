his is to confirm the pipeline issue has been resolved and is now running successfully. The original error message was misleading and did not point to the root cause.

The resolution involved creating several new Azure resources. To ensure this is documented and properly managed, I will be creating separate tickets for the following:

Creating a new Storage Account.

Setting up a Managed Identity.

Granting the necessary roles to the identity.

Configuring required DNS records.

Additionally, we've identified a need for more Kubernetes resources to support the CRD operator we are using."

Why it's better:

Structured: Separates the resolution from the action items.

Professional: Uses clear, formal language.

Scannable: The bullet points make the required work easy to digest.

Additional Finding:
We have identified that the current Kubernetes cluster requires additional resource allocations (CPU/Memory) to reliably support the CRD Operator.





# Explicit mode to match your backend/read/write groups
deploymentMode: Microservices

loki:
  auth_enabled: false

  # Retention & limits
  limits_config:
    allow_structured_metadata: true
    retention_period: 744h  # 31 days

  # TSDB + Azure object store
  schemaConfig:
    configs:
      - from: "2024-04-01"
        store: tsdb
        object_store: azure
        schema: v13
        index:
          prefix: loki_index_
          period: 24h

  # >>> IMPORTANT <<<
  # Use the *direct* storage_config stanza for Azure (prevents the helper from
  # requiring loki.storage.bucketNames.* which caused your error).
  storage_config:
    azure:
      account_name: xxxxxxxx
      container_name: loki
      use_federated_token: true

  # Ruler storage is defined inside Loki config as well
  ruler:
    storage:
      type: azure
      azure:
        account_name: xxxxxx
        container_name: ruler
        use_federated_token: true

  # Compactor feature flags (NOT the replica group)
  compactor:
    retention_enabled: true

# ServiceAccount + Workload Identity
serviceAccount:
  create: true
  name: xxxxxxx
  annotations:
    azure.workload.identity/client-id: "exxx"

# Label pods so WI works
backend:
  replicas: 1
  podLabels:
    azure.workload.identity/use: "true"

read:
  replicas: 1
  podLabels:
    azure.workload.identity/use: "true"

write:
  replicas: 2
  podLabels:
    azure.workload.identity/use: "true"

# Disable singleBinary & other groups (you're in Microservices mode)
singleBinary:
  replicas: 0
ingester:
  replicas: 0
querier:
  replicas: 0
queryFrontend:
  replicas: 0
queryScheduler:
  replicas: 0
distributor:
  replicas: 0
compactor:
  replicas: 0
indexGateway:
  replicas: 0
bloomCompactor:
  replicas: 0
bloomGateway:
  replicas: 0

# Optional: expose OTLP at the gateway
gateway:
  enabled: true
  otlp:
    enabled: true
    grpc:
      enabled: true
      service:
        port: 4317
    http:
      enabled: true
      service:
        port: 4320
























Option 3 says we'll keep Azure Monitor for metrics of non-AKS components, yet later on we say in Recommendation:

Metrics: Prometheus as source of truth via exporter/Collector pull; Grafana for visualization. Use Azure Managed Prometheus if you prefer a managed backend.





All our applications send trace data using the OpenTelemetry standard to a central collector, which then forwards it to our chosen tracing database (either Jaeger or Tempo), I was trying to be too broad I should have just keep to the content"
The second will be  for services that require Azure APM experiences, and will require  secondary pipeline for a specific subset of services that will send their traces to the second destination



All our applications send trace data using the OpenTelemetry standard to a central collector, which then forwards it to our chosen tracing database (either Jaeger or Tempo)."
This is the conditional, secondary pipeline for a specific subset of services
a select group of services will send their traces to a second destination.
App Insights: Short for Azure Application Insights. This is a commercial Application Performance Management (APM) service on Microsoft Azure. It provides deep monitoring, performance analytics, and smart detection.

"only for services that require Azure APM experiences

mkdir -p /etc/apt/keyrings
curl -sL https://packages.microsoft.com/keys/microsoft.asc | gpg --dearmor | sudo tee /etc/apt/keyrings/microsoft.gpg > /dev/null

SUITE=$(lsb_release -cs)
echo "deb [arch=amd64 signed-by=/etc/apt/keyrings/microsoft.gpg] https://packages.microsoft.com/repos/azure-cli/ $SUITE main" | sudo tee /etc/apt/sources.list.d/azure-cli.list


sudo apt-get update
sudo apt-get install azure-cli





service/otel-collector created
servicemonitor.monitoring.coreos.com/otel-collector-monitor created
Error from server (InternalError): error when applying patch:
{"metadata":{"annotations":{"kubectl.kubernetes.io/last-applied-configuration":"{\"apiVersion\":\"opentelemetry.io/v1beta1\",\"kind\":\"OpenTelemetryCollector\",\"metadata\":{\"annotations\":{},\"labels\":{\"app\":\"opentelemetry-collector\",\"hbt.cmhc.schl.gc.ca/owner\":\"devops\"},\"name\":\"otel-collector\",\"namespace\":\"monitoring\"},\"spec\":{\"config\":{\"exporters\":{\"debug\":{\"verbosity\":\"detailed\"},\"otlp/jaeger\":{\"endpoint\":\"jaeger-collector.monitoring.svc.cluster.local:4317\",\"tls\":{\"insecure\":true}},\"otlphttp\":{\"endpoint\":\"http://loki-write.monitoring.svc.cluster.local:3100/otlp\",\"headers\":{\"X-Scope-OrgID\":\"tenant-1\"},\"tls\":{\"insecure\":true}},\"prometheus\":{\"const_labels\":{\"k8s_cluster\":\"clustername\"},\"enable_open_metrics\":true,\"endpoint\":\"0.0.0.0:8889\",\"namespace\":\"monitoring\",\"send_timestamps\":true}},\"extensions\":{\"health_check\":{\"endpoint\":\"0.0.0.0:13133\"},\"pprof\":{\"endpoint\":\"0.0.0.0:1777\"},\"zpages\":{\"endpoint\":\"0.0.0.0:55679\"}},\"processors\":{\"batch\":{\"send_batch_max_size\":4096,\"send_batch_size\":1024,\"timeout\":\"200ms\"},\"groupbytrace\":{},\"memory_limiter\":{\"check_interval\":\"5s\",\"limit_mib\":512,\"limit_percentage\":80,\"spike_limit_mib\":64},\"metricstransform\":{\"transforms\":[{\"action\":\"update\",\"include\":\"system.cpu.usage\",\"operations\":[{\"action\":\"add_label\",\"new_label\":\"host.name\",\"new_value\":\"host.name\"},{\"action\":\"add_label\",\"new_label\":\"cluster.name\",\"new_value\":\"clustername\"}]},{\"action\":\"update\",\"include\":\"system.memory.usage\",\"operations\":[{\"action\":\"add_label\",\"new_label\":\"host.name\",\"new_value\":\"host.name\"},{\"action\":\"add_label\",\"new_label\":\"cluster.name\",\"new_value\":\"clustername\"}]}]},\"resource\":{\"attributes\":[{\"action\":\"insert\",\"key\":\"cluster.name\",\"value\":\"clustername\"},{\"action\":\"insert\",\"key\":\"exporter\",\"value\":\"node-exporter\"}]},\"resourcedetection\":{\"detectors\":[\"env\",\"system\"],\"override\":false,\"timeout\":\"2s\"},\"transform\":{\"log_statements\":[{\"context\":\"log\",\"statements\":[\"set(attributes[\\\"processing.note\\\"], \\\"Log enriched with resource and trace context\\\")\",\"set(attributes[\\\"service.name\\\"], resource.attributes[\\\"service.name\\\"])\",\"set(attributes[\\\"k8s.pod.name\\\"], resource.attributes[\\\"k8s.pod.name\\\"])\",\"set(attributes[\\\"k8s.node.name\\\"], resource.attributes[\\\"k8s.node.name\\\"])\",\"set(attributes[\\\"host.name\\\"], resource.attributes[\\\"host.name\\\"])\",\"set(attributes[\\\"cluster.name\\\"], resource.attributes[\\\"cluster.name\\\"])\",\"set(attributes[\\\"trace_id\\\"], trace_id)\",\"set(attributes[\\\"span_id\\\"], span_id)\"]}]}},\"receivers\":{\"jaeger\":{\"protocols\":{\"grpc\":{\"endpoint\":\"0.0.0.0:14250\"},\"thrift_compact\":{\"endpoint\":\"0.0.0.0:6831\"},\"thrift_http\":{\"endpoint\":\"0.0.0.0:14268\"}}},\"loki\":{\"protocols\":{\"http\":{\"endpoint\":\"0.0.0.0:4318\"}}},\"otlp\":{\"protocols\":{\"grpc\":{\"endpoint\":\"0.0.0.0:4317\"},\"http\":{\"endpoint\":\"0.0.0.0:4318\"}}},\"prometheus/node\":{\"config\":{\"scrape_configs\":[{\"job_name\":\"node-exporter\",\"scrape_interval\":\"10s\",\"static_configs\":[{\"labels\":{\"cluster\":\"clustername\",\"job\":\"node-exporter\"},\"targets\":[\"prometheus-prometheus-node-exporter.monitoring.svc:9100\"]}]}]}}},\"service\":{\"extensions\":[\"health_check\",\"pprof\",\"zpages\"],\"pipelines\":{\"logs\":{\"exporters\":[\"debug\",\"otlphttp\"],\"processors\":[\"memory_limiter\",\"resourcedetection\",\"resource\",\"transform\",\"batch\"],\"receivers\":[\"otlp\",\"loki\"]},\"metrics\":{\"exporters\":[\"debug\",\"prometheus\"],\"processors\":[\"memory_limiter\",\"resourcedetection\",\"resource\",\"metricstransform\",\"batch\"],\"receivers\":[\"otlp\",\"prometheus/node\"]},\"traces\":{\"exporters\":[\"debug\",\"otlp/jaeger\"],\"processors\":[\"memory_limiter\",\"resourcedetection\",\"resource\",\"groupbytrace\",\"batch\"],\"receivers\":[\"otlp\",\"jaeger\"]}},\"telemetry\":{\"metrics\":{\"level\":\"detailed\"}}}},\"env\":[{\"name\":\"K8S_NODE_NAME\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"spec.nodeName\"}}},{\"name\":\"K8S_POD_NAME\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.name\"}}},{\"name\":\"K8S_POD_NAMESPACE\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.namespace\"}}},{\"name\":\"K8S_POD_IP\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"status.podIP\"}}}],\"image\":\"otel/opentelemetry-collector-contrib:0.128.0\",\"mode\":\"deployment\",\"ports\":[{\"name\":\"otlp-grpc\",\"port\":4317,\"protocol\":\"TCP\"},{\"name\":\"otlp-http\",\"port\":4318,\"protocol\":\"TCP\"},{\"name\":\"jaeger-grpc\",\"port\":14250,\"protocol\":\"TCP\"},{\"name\":\"jaeger-thrift-c\",\"port\":6831,\"protocol\":\"TCP\"},{\"name\":\"jaeger-thrift-h\",\"port\":14268,\"protocol\":\"TCP\"},{\"name\":\"metrics\",\"port\":8888,\"protocol\":\"TCP\"},{\"name\":\"prom-metrics\",\"port\":8889,\"protocol\":\"TCP\"},{\"name\":\"health\",\"port\":13133,\"protocol\":\"TCP\"}],\"replicas\":2,\"resources\":{\"limits\":{\"cpu\":\"1000m\",\"memory\":\"1600Mi\"},\"requests\":{\"cpu\":\"500m\",\"memory\":\"800Mi\"}},\"serviceAccount\":\"opentelemetry-collector\"}}\n"}},"spec":{"config":{"processors":{"resource":{"attributes":[{"action":"insert","key":"cluster.name","value":"clustername"},{"action":"insert","key":"exporter","value":"node-exporter"}]}},"receivers":{"loki":{"protocols":{"grpc":null,"http":{"include_metadata":null}},"use_incoming_timestamp":null}}},"ports":[{"name":"otlp-grpc","port":4317,"protocol":"TCP"},{"name":"otlp-http","port":4318,"protocol":"TCP"},{"name":"jaeger-grpc","port":14250,"protocol":"TCP"},{"name":"jaeger-thrift-c","port":6831,"protocol":"TCP"},{"name":"jaeger-thrift-h","port":14268,"protocol":"TCP"},{"name":"metrics","port":8888,"protocol":"TCP"},{"name":"prom-metrics","port":8889,"protocol":"TCP"},{"name":"health","port":13133,"protocol":"TCP"}],"resources":{"limits":{"cpu":"1000m"}}}}
to:
Resource: "opentelemetry.io/v1beta1, Resource=opentelemetrycollectors", GroupVersionKind: "opentelemetry.io/v1beta1, Kind=OpenTelemetryCollector"
Name: "otel-collector", Namespace: "monitoring"
for: "/azp/agent/_work/62/s/kustomize/overlays/EDIT/05opentelemetry/kustomization-output.yaml": error when patching "/azp/agent/_work/62/s/kustomize/overlays/EDIT/05opentelemetry/kustomization-output.yaml": Internal error occurred: failed calling webhook "mopentelemetrycollectorbeta.kb.io": failed to call webhook: Post "https://opentelemetry-operator-webhook.monitoring.svc:443/mutate-opentelemetry-io-v1beta1-opentelemetrycollector?timeout=10s": tls: failed to verify certificate: x509: certificate signed by unknown authority
*** Done





#collector.yaml 

apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: otel-collector
  namespace: monitoring
  labels:
    app: opentelemetry-collector
spec:
  mode: deployment
  image: otel/opentelemetry-collector-contrib:0.128.0
  serviceAccount: opentelemetry-collector
  replicas: 2
  
  ports:
    - name: otlp-grpc
      port: 4317
      protocol: TCP
    - name: otlp-http
      port: 4318
      protocol: TCP
    - name: jaeger-grpc
      port: 14250
      protocol: TCP
    - name: jaeger-thrift-c  
      port: 6831
      protocol: TCP
    - name: jaeger-thrift-h  
      port: 14268
      protocol: TCP
    - name: metrics
      port: 8888
      protocol: TCP
    - name: prom-metrics
      port: 8889
      protocol: TCP
    - name: health
      port: 13133
      protocol: TCP

  env:
    - name: K8S_NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    - name: K8S_POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: K8S_POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: K8S_POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP

  resources:
    requests:
      cpu: 500m
      memory: 800Mi
    limits:
      cpu: 1000m
      memory: 1600Mi

  config: |
    extensions:
      health_check:
        endpoint: "0.0.0.0:13133"
      pprof:
        endpoint: "0.0.0.0:1777"
      zpages:
        endpoint: "0.0.0.0:55679"

    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: "0.0.0.0:4317"
          http:
            endpoint: "0.0.0.0:4318"
      jaeger:
        protocols:
          grpc:
            endpoint: "0.0.0.0:14250"
          thrift_compact:
            endpoint: "0.0.0.0:6831"
          thrift_http:
            endpoint: "0.0.0.0:14268"
      loki:
        protocols:
          http:
            endpoint: "0.0.0.0:4318"
      prometheus/node:
        config:
          scrape_configs:
            - job_name: 'node-exporter'
              scrape_interval: 10s
              static_configs:
                - targets: ['prometheus-prometheus-node-exporter.monitoring.svc:9100']
                  labels:
                    job: 'node-exporter'
                    cluster: 'clustername'

    processors:
      batch:
        timeout: 200ms
        send_batch_size: 1024
        send_batch_max_size: 4096
      memory_limiter:
        check_interval: 5s
        limit_percentage: 80
        spike_limit_mib: 64
        limit_mib: 512
      groupbytrace: {}
      resource:
        attributes:
          - key: cluster.name
            value: clustername
            action: insert
          - key: exporter
            value: "node-exporter"
            action: insert
      resourcedetection:
        detectors: [env, system]
        override: false
        timeout: 2s
      transform:
        log_statements:
          - context: log
            statements:
              - set(attributes["processing.note"], "Log enriched with resource and trace context")
              - set(attributes["service.name"], resource.attributes["service.name"])
              - set(attributes["k8s.pod.name"], resource.attributes["k8s.pod.name"])
              - set(attributes["k8s.node.name"], resource.attributes["k8s.node.name"])
              - set(attributes["host.name"], resource.attributes["host.name"])
              - set(attributes["cluster.name"], resource.attributes["cluster.name"])
              - set(attributes["trace_id"], trace_id)
              - set(attributes["span_id"], span_id)
      metricstransform:
        transforms:
          - include: system.cpu.usage
            action: update
            operations:
              - action: add_label
                new_label: host.name
                new_value: host.name
              - action: add_label
                new_label: cluster.name
                new_value: clustername
          - include: system.memory.usage
            action: update
            operations:
              - action: add_label
                new_label: host.name
                new_value: host.name
              - action: add_label
                new_label: cluster.name
                new_value: clustername

    exporters:
      debug:
        verbosity: detailed
      otlphttp:
        endpoint: http://loki-write.monitoring.svc.cluster.local:3100/otlp
        tls:
          insecure: true
        headers:
          X-Scope-OrgID: tenant-1
      prometheus:
        endpoint: "0.0.0.0:8889"  
        namespace: monitoring
        const_labels:
          k8s_cluster: clustername
        send_timestamps: true
        enable_open_metrics: true
      otlp/jaeger:
        endpoint: jaeger-collector.monitoring.svc.cluster.local:4317
        tls:
          insecure: true

    service:
      telemetry:
        metrics:
          level: detailed
      extensions: [health_check, pprof, zpages]
      pipelines:
        metrics:
          receivers: [otlp, prometheus/node]
          processors: [memory_limiter, resourcedetection, resource, metricstransform, batch]
          exporters: [debug, prometheus]
        traces:
          receivers: [otlp, jaeger]
          processors: [memory_limiter, resourcedetection, resource, groupbytrace, batch]
          exporters: [debug, otlp/jaeger]
        logs:
          receivers: [otlp, loki]
          processors: [memory_limiter, resourcedetection, resource, transform, batch]
          exporters: [debug, otlphttp]


#serviceMetric.yaml
apiVersion: v1
kind: Service
metadata:
  name: otel-collector
  namespace: monitoring
  labels:
    app: opentelemetry-collector
spec:
  selector:
    app: opentelemetry-collector
  ports:
    - name: prom-metrics
      port: 8889
      targetPort: 8889
    - name: metrics
      port: 8888
      targetPort: 8888
    - name: otlp-grpc
      port: 4317
      targetPort: 4317
    - name: otlp-http
      port: 4318
      targetPort: 4318

#base/Kustomization 

namespace: monitoring

resources:
- collector.yaml
- serviceMetric.yaml






#overlay
#ServiceMonitor.yaml

apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: otel-collector-monitor
  namespace: monitoring
  labels:
    release: kube-prometheus-stack
spec:
  selector:
    matchLabels:
      app: opentelemetry-collector
  namespaceSelector:
    matchNames: ["monitoring"]
  endpoints:
    - port: prom-metrics
      interval: 10s
      path: /metrics
      honorLabels: true
      relabelings:
        - action: labelmap
          regex: __meta_kubernetes_pod_label_(.+)


#collector-patch.yaml

apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: otel-collector
  namespace: monitoring
spec:
  resources:
    limits:
      cpu: "1000m"
  ports:
    - name: otlp-grpc
      port: 4317
      protocol: TCP
    - name: otlp-http
      port: 4318
      protocol: TCP
    - name: jaeger-grpc
      port: 14250
      protocol: TCP
    - name: jaeger-thrift-c
      port: 6831
      protocol: TCP
    - name: jaeger-thrift-h
      port: 14268
      protocol: TCP
    - name: metrics
      port: 8888
      protocol: TCP
    - name: prom-metrics
      port: 8889
      protocol: TCP
    - name: health
      port: 13133
      protocol: TCP


#Overlay/kustomization

namespace: monitoring

resources:
- ../../base

patches:
  - target:
      kind: MutatingWebhookConfiguration
      name: opentelemetry-operator-mutating-webhook-configuration
    path: opentelemetry-webhook-patch.yaml

  - target:
      kind: ServiceMonitor
      name: otel-collector-monitor
    path: ServiceMonitor.yaml

  - target:
      kind: OpenTelemetryCollector
      name: otel-collector
    path: collector-patch.yaml
